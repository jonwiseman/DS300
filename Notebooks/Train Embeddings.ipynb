{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to train document embeddings on our Reddit text dataset.  I follow the general outline presented in this [article](https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html#sphx-glr-auto-examples-tutorials-run-doc2vec-lee-py) from gensim.  The general outline is as follows:\n",
    "\n",
    "(1) Read in subreddit data  \n",
    "(2) Create model objects \n",
    "(3) Search for optimal dimensions over range 2-100  \n",
    "(4) Search for optimal dimensions over range 2-10  \n",
    "(5) Save models  \n",
    "\n",
    "This will be done for both the subreddit and post data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on Subreddits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in subs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by reading in the subreddits we will train the document embeddings on.  Notice that I don't include reading, since there are very few comments for the reading subreddits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['art', 'gaming', 'music', 'politics_news', 'science', 'sports', 'tech'] # categories\n",
    "stem = 'lemma' # stemming type to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for cat in cats:\n",
    "    os.chdir(fr'..\\Data\\{cat}\\Processed\\{stem}')\n",
    "    files = glob.glob('*.json') # grab all .json files and store their names in a files list\n",
    "    for file in files: # read each .json file and extract its comments\n",
    "        with open(fr'..\\Data\\{cat}\\Processed\\{stem}\\{file}', 'r') as f:\n",
    "            comments = json.load(f)\n",
    "        documents.append((' '.join([comment['comment'] for comment in comments]), cat, cat, file.split('.json')[0])) # extra cat for label encoding\n",
    "        \n",
    "documents = np.array(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder() # encode categories using LabelEncoder\n",
    "documents[:, 2] = encoder.fit_transform(documents[:, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create model objects**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Doc2Vec model requires a corpus (a list of tokenized, labeled documents) to build a vocabulary to train embeddings.  We'll tokenize each document in our list using NLTK's [word_tokenize](https://www.nltk.org/api/nltk.tokenize.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(documents[:, 0])\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(docs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Search for optimal dimension using k-means measures**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My knowledge of ideal embedding dimensions is very limited.  As such, I'll treat the dimension as a hyperparameter to train with our model.  My assumption is that the dimension that balances silhouette score and model accuracy (as measured by homogeneity, completeness, and v-measure) the best is the ideal dimension to train embeddings on; measures are tested on a k-means model with n_clusters set to the number of categories.  Again, this is probably an inaccurate way to go about it, but I feel it's a reasonable enough start.  \n",
    "\n",
    "We'll start by looking at embedding dimensions from 2 to 100 (with a step of 5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector size: 2\n",
      "Silhouette score: 0.5192214250564575\n",
      "Homogeneity: 0.503\n",
      "Completeness: 0.508\n",
      "V-measure: 0.505\n",
      "\n",
      "Vector size: 7\n",
      "Silhouette score: 0.22882992029190063\n",
      "Homogeneity: 0.595\n",
      "Completeness: 0.609\n",
      "V-measure: 0.602\n",
      "\n",
      "Vector size: 12\n",
      "Silhouette score: 0.11338256299495697\n",
      "Homogeneity: 0.679\n",
      "Completeness: 0.684\n",
      "V-measure: 0.681\n",
      "\n",
      "Vector size: 17\n",
      "Silhouette score: 0.038808673620224\n",
      "Homogeneity: 0.493\n",
      "Completeness: 0.502\n",
      "V-measure: 0.497\n",
      "\n",
      "Vector size: 22\n",
      "Silhouette score: 0.02382996305823326\n",
      "Homogeneity: 0.402\n",
      "Completeness: 0.408\n",
      "V-measure: 0.405\n",
      "\n",
      "Vector size: 27\n",
      "Silhouette score: 0.0020397771149873734\n",
      "Homogeneity: 0.426\n",
      "Completeness: 0.474\n",
      "V-measure: 0.449\n",
      "\n",
      "Vector size: 32\n",
      "Silhouette score: 0.007579568773508072\n",
      "Homogeneity: 0.607\n",
      "Completeness: 0.650\n",
      "V-measure: 0.628\n",
      "\n",
      "Vector size: 37\n",
      "Silhouette score: 0.011560635641217232\n",
      "Homogeneity: 0.539\n",
      "Completeness: 0.564\n",
      "V-measure: 0.551\n",
      "\n",
      "Vector size: 42\n",
      "Silhouette score: 0.01644926704466343\n",
      "Homogeneity: 0.736\n",
      "Completeness: 0.765\n",
      "V-measure: 0.750\n",
      "\n",
      "Vector size: 47\n",
      "Silhouette score: 0.013223346322774887\n",
      "Homogeneity: 0.622\n",
      "Completeness: 0.665\n",
      "V-measure: 0.643\n",
      "\n",
      "Vector size: 52\n",
      "Silhouette score: 0.01646733470261097\n",
      "Homogeneity: 0.704\n",
      "Completeness: 0.746\n",
      "V-measure: 0.725\n",
      "\n",
      "Vector size: 57\n",
      "Silhouette score: 0.014554525725543499\n",
      "Homogeneity: 0.588\n",
      "Completeness: 0.608\n",
      "V-measure: 0.598\n",
      "\n",
      "Vector size: 62\n",
      "Silhouette score: 0.013344287872314453\n",
      "Homogeneity: 0.593\n",
      "Completeness: 0.628\n",
      "V-measure: 0.610\n",
      "\n",
      "Vector size: 67\n",
      "Silhouette score: 0.01842295192182064\n",
      "Homogeneity: 0.595\n",
      "Completeness: 0.625\n",
      "V-measure: 0.610\n",
      "\n",
      "Vector size: 72\n",
      "Silhouette score: 0.01147297490388155\n",
      "Homogeneity: 0.545\n",
      "Completeness: 0.567\n",
      "V-measure: 0.556\n",
      "\n",
      "Vector size: 77\n",
      "Silhouette score: 0.018597513437271118\n",
      "Homogeneity: 0.569\n",
      "Completeness: 0.642\n",
      "V-measure: 0.603\n",
      "\n",
      "Vector size: 82\n",
      "Silhouette score: 0.012407012283802032\n",
      "Homogeneity: 0.628\n",
      "Completeness: 0.655\n",
      "V-measure: 0.641\n",
      "\n",
      "Vector size: 87\n",
      "Silhouette score: 0.012582695111632347\n",
      "Homogeneity: 0.487\n",
      "Completeness: 0.587\n",
      "V-measure: 0.533\n",
      "\n",
      "Vector size: 92\n",
      "Silhouette score: 0.011123141273856163\n",
      "Homogeneity: 0.671\n",
      "Completeness: 0.682\n",
      "V-measure: 0.676\n",
      "\n",
      "Vector size: 97\n",
      "Silhouette score: 0.014276755042374134\n",
      "Homogeneity: 0.661\n",
      "Completeness: 0.727\n",
      "V-measure: 0.692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for vec_size in range(2, 100, 5):\n",
    "    model = gensim.models.doc2vec.Doc2Vec(dm=0, vector_size=vec_size, min_count=2, epochs=100)\n",
    "    model.build_vocab(tagged_data)\n",
    "    model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    \n",
    "    doc_vectors = []\n",
    "    for i in range(0, len(tagged_data)):\n",
    "        doc_vectors.append(model[str(i)])\n",
    "\n",
    "    doc_vectors = np.array(doc_vectors)\n",
    "    scaler = StandardScaler()\n",
    "    doc_scaled = scaler.fit_transform(doc_vectors)\n",
    "    \n",
    "    km = KMeans(n_clusters=len(cats), init='k-means++')\n",
    "    km.fit(doc_scaled)\n",
    "    print(f'Vector size: {vec_size}')\n",
    "    print(f'Silhouette score: {metrics.silhouette_score(doc_scaled, labels=km.labels_.reshape(-1))}')\n",
    "    labels = np.array(documents[:, 2], dtype=int)\n",
    "    print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "    print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "    print(\"V-measure: %0.3f\\n\" % metrics.v_measure_score(labels, km.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the dimensions ranging from 2-10 give the best balance between sillhouette score and accuracy.  Notice how sillhouete score goes down dramatically as the number of dimensions increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Refine: search dimensions 2-10**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll search in the range 2-10 to get a better look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector size: 2\n",
      "Silhouette score: 0.5725953578948975\n",
      "Homogeneity: 0.471\n",
      "Completeness: 0.481\n",
      "V-measure: 0.476\n",
      "Inertia: 1.9910777133684405\n",
      "\n",
      "Vector size: 3\n",
      "Silhouette score: 0.48049601912498474\n",
      "Homogeneity: 0.662\n",
      "Completeness: 0.667\n",
      "V-measure: 0.665\n",
      "Inertia: 6.612958480170278\n",
      "\n",
      "Vector size: 4\n",
      "Silhouette score: 0.39680349826812744\n",
      "Homogeneity: 0.777\n",
      "Completeness: 0.785\n",
      "V-measure: 0.781\n",
      "Inertia: 23.123259042838527\n",
      "\n",
      "Vector size: 5\n",
      "Silhouette score: 0.30829083919525146\n",
      "Homogeneity: 0.720\n",
      "Completeness: 0.731\n",
      "V-measure: 0.725\n",
      "Inertia: 43.48196606527199\n",
      "\n",
      "Vector size: 6\n",
      "Silhouette score: 0.2835235297679901\n",
      "Homogeneity: 0.688\n",
      "Completeness: 0.690\n",
      "V-measure: 0.689\n",
      "Inertia: 61.54994779152912\n",
      "\n",
      "Vector size: 7\n",
      "Silhouette score: 0.20817075669765472\n",
      "Homogeneity: 0.705\n",
      "Completeness: 0.716\n",
      "V-measure: 0.711\n",
      "Inertia: 93.0012925107917\n",
      "\n",
      "Vector size: 8\n",
      "Silhouette score: 0.1611940711736679\n",
      "Homogeneity: 0.700\n",
      "Completeness: 0.709\n",
      "V-measure: 0.705\n",
      "Inertia: 121.35718024162634\n",
      "\n",
      "Vector size: 9\n",
      "Silhouette score: 0.12222223728895187\n",
      "Homogeneity: 0.633\n",
      "Completeness: 0.669\n",
      "V-measure: 0.651\n",
      "Inertia: 154.4150415694712\n",
      "\n",
      "Vector size: 10\n",
      "Silhouette score: 0.13000449538230896\n",
      "Homogeneity: 0.501\n",
      "Completeness: 0.514\n",
      "V-measure: 0.507\n",
      "Inertia: 180.55303735086838\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for vec_size in range(2, 11):\n",
    "    model = gensim.models.doc2vec.Doc2Vec(dm=0, vector_size=vec_size, min_count=2, epochs=100)\n",
    "    model.build_vocab(tagged_data)\n",
    "    model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    \n",
    "    doc_vectors = []\n",
    "    for i in range(0, len(tagged_data)):\n",
    "        doc_vectors.append(model[str(i)])\n",
    "\n",
    "    doc_vectors = np.array(doc_vectors)\n",
    "    scaler = StandardScaler()\n",
    "    doc_scaled = scaler.fit_transform(doc_vectors)\n",
    "    \n",
    "    km = KMeans(n_clusters=len(cats), init='k-means++')\n",
    "    km.fit(doc_scaled)\n",
    "    print(f'Vector size: {vec_size}')\n",
    "    print(f'Silhouette score: {metrics.silhouette_score(doc_scaled, labels=km.labels_.reshape(-1))}')\n",
    "    labels = np.array(documents[:, 2], dtype=int)\n",
    "    print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "    print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "    print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
    "    print(f'Inertia: {km.inertia_}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimension 4 seems to give the best balance between high accuracy and good clustering (as measured by sillhouette score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select model and save**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a model using dimension 4 and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(dm=0, vector_size=4, min_count=2, epochs=100)\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'..\\Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('subs.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll repeat the same process as above, but we'll assume that dimension 4 is ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in posts:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for cat in cats:\n",
    "    os.chdir(fr'..\\Data\\{cat}\\Processed\\{stem}')\n",
    "    files = glob.glob('*.json')\n",
    "    for file in files:\n",
    "        with open(fr'..\\Data\\{cat}\\Processed\\{stem}\\{file}', 'r') as f:\n",
    "            comments = json.load(f)\n",
    "        df = pd.DataFrame(comments)\n",
    "        posts = df['post_id'].unique()\n",
    "        for post in posts:\n",
    "            documents.append((' '.join(list(df[df['post_id'] == post]['comment'])), cat, cat, file.split('.json')[0]))\n",
    "        \n",
    "documents = np.array(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "documents[:, 2] = encoder.fit_transform(documents[:, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(documents[:, 0])\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(docs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(dm=0, vector_size=4, min_count=2, epochs=100)\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'..\\Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('posts.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
